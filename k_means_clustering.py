# -*- coding: utf-8 -*-
"""K-Means_Clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13QmbgBGXIVUJCdaUJIqwdpOVxNDU1HZ-

# ***K Means Clustering***
"""

# Importing Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Importing Training Data 
TrainingData = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/emnist-letters-train.csv")
TrainingData

# Initializing X (Feature Values)
X_Table = TrainingData.drop('23', axis=1)
print('X_Table Shape : ', X_Table.shape)
print(X_Table)

X = np.array(X_Table)
print('X Shape : ', X.shape)
print(X)

# Initializing Y (Labels)
Y_Table = TrainingData['23']
print('Y_Table Shape : ', Y_Table.shape)
print(Y_Table)

Y = np.array([Y_Table]).T
print('Y Shape : ', Y.shape)
print(Y)

# Randomly Choosing Centroids
K = 26
Centroids_Table = X_Table.sample(n=K)
Centroids = np.array(Centroids_Table)
print('Centroids Shape : ', Centroids.shape)
print(Centroids)

# Main
Iterations = 500
z=0
while(z < Iterations):
  Distances = np.zeros((X.shape[0], 26))
  for i in range(26):
    Distances[:,i] = np.array(np.sqrt(np.sum((X - Centroids[i])**2, axis=1)))

  Min = np.array([np.min(Distances, axis=1)]).T

  HotOne = (Distances == Min).astype(int)
  
  for i in range(26):
    HotOne[:,i]*=(i+1)
  Cluster = np.sum(HotOne, axis=1)

  X_Table['Cluster'] = Cluster
  Centroids_New_Table = X_Table.groupby(['Cluster']).mean()
  Centroids_New = np.array(Centroids_New_Table)
  X_Table.pop('Cluster')

  if(np.sum((Centroids_New - Centroids)**2) == 0):
    break

  Centroids_Table = Centroids_New_Table
  Centroids = Centroids_New
  z+=1

Y_Predicted = Cluster

# Output
print('EXPECTED vs PREDICTED')
print(np.concatenate((Y, np.array([Y_Predicted]).T), axis=1))

temp = (Y == 10).astype(int).T

a = temp*Y_Predicted
a = a[a!=0]
count = np.zeros(26)
for i in a:
  count[i-1]+=1

for i in range(1,27):
  print(i, '\t', count[i-1])

# Cluster Number may be different but the data is getting grouped into 26 different groups and Algorithm is working fine, i.e., Updating Centroids and Clustering Data into 26 different groups

