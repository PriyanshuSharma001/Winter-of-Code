# -*- coding: utf-8 -*-
"""Logistic_Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fyaHCKxBCmO_CC3x0IkJA57KNHoOeK2c

# ***LOGISTIC REGRESSION***
"""

# Importing Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""## ***Training***"""

# Sigmoid Function
def SigmoidFunction(X):
  return 1/(1+np.exp(-X))

# Function to generate Hypothesis
def Hypothesis(X, theta):
  return SigmoidFunction(np.dot(X, theta))

# Cost Function
def Cost(X, Y1, theta):
    H = Hypothesis(X, theta)
    return -(np.sum(Y1*np.log(H) + (1-Y1)*np.log(1-H)))/(len(X))

# Logistic Regression Training Function
def LogisticRegressionTraining(X, Y_HotOne, theta, LearningRate, Iterations, BatchSize):
  m = BatchSize
  X_Clipped = X[0:BatchSize]
  Y_HotOne_Clipped = Y_HotOne[0:BatchSize]

  for i in range(0, Iterations):
    H = Hypothesis(X_Clipped, theta)
    theta = theta - LearningRate*(np.dot(X_Clipped.T, H - Y_HotOne_Clipped) / m)

  return theta

# Importing Training Data
TrainingData = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/emnist-letters-train.csv")
TrainingData

# Initializing X (Feature Values) for training
X = np.array(TrainingData.drop('23', axis=1)) / 255
X = np.concatenate((np.ones((X.shape[0],1)),X), axis=1)

print('X Shape : ', X.shape)
print(X)

# Initializing Y (Labels) for training
Y = (np.array([TrainingData['23']])).T

print('Y Shape : ', Y.shape)
print(Y)

# Determining Different Classes of Output
Classes = np.unique(Y)
print('Classes : ')
print(Classes)

# Hot-One Notation for Y
Y_HotOne = np.zeros((X.shape[0], len(Classes)))

Num_Classes = len(Classes)
m = len(Y)
for i in range(m):
  Y_HotOne[i, Y[i]-1] = 1

print('Y_HotOne Shape : ', Y_HotOne.shape)
print(Y_HotOne)

# Randomly Initializing theta
theta = np.zeros((X.shape[1], len(np.unique(Y))))
print('theta Shape : ', theta.shape)
print(theta)

# Mian / Calculating theta
LearningRate = 0.1
Iterations = 100
BatchSize = 88799

theta = LogisticRegressionTraining(X, Y_HotOne, theta, LearningRate, Iterations, BatchSize)
print('theta Shape : ', theta.shape)
print(theta)
print('\nCost : ', Cost(X, Y_HotOne, theta))

# Generating Hypothesis
H = Hypothesis(X, theta)

print('H Shape : ', H.shape)
print(H)

# Hot-One Notation for Hypothesis
H_HotOne = np.zeros(H.shape)

for row in range(0, H.shape[0]):
  max = np.max(H[row,:])

  for column in range(0, H.shape[1]):
    if H[row, column] == max :
      H_HotOne[row, column] = 1

print('H_HotOne Shape : ', H_HotOne.shape)
print(H_HotOne)

# Generating Predicted Output
Y_Predicted = np.zeros((Y.shape[0], 1))
rows = H_HotOne.shape[0]
cols = H_HotOne.shape[1]

for i in range(rows):
  for j in range(cols):
    if(H_HotOne[i][j] == 1):
      Y_Predicted[i][0] = j+1
      break

print('Y_Predicted Shape : ', Y_Predicted.shape)
print(Y_Predicted)

# Comparing Expected vs Prediction
print('EXPECTED vs PREDICTED')
print(np.concatenate((Y, Y_Predicted), axis=1))

# Calculating Accuracy
count = 0
for i in range(len(Y_HotOne)):
  if np.sum(H_HotOne[i] * Y_HotOne[i]) == 1:
    count+=1;

print('Accuracy : ', (count/len(Y_HotOne))*100, '%')

"""## ***Testing***"""

# Importing Testing Data
TestingData = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/emnist-letters-test.csv")
TestingData

# Initializing X_test for testing
X_test = np.array(TestingData.drop('1', axis=1)) / 255
X_test = np.concatenate((np.ones((X_test.shape[0],1)),X_test), axis=1)

print('X_test Shape : ', X_test.shape)
print(X_test)

# Initializing Y_test for testing
Y_test = (np.array([TestingData['1']])).T

print('Y_test Shape : ', Y_test.shape)
print(Y_test)

# Generating Hypothesis
H_test = Hypothesis(X_test, theta)

print('H_test Shape : ', H_test.shape)
print(H_test)

# Hot-One Notation for Hypothesis_test
H_test_HotOne = np.zeros(H_test.shape)

for row in range(0, H_test.shape[0]):
  max = np.max(H_test[row,:])

  for column in range(0, H_test.shape[1]):
    if H_test[row, column] == max :
      H_test_HotOne[row, column] = 1

# Generating Predicted test Output
Y_test_Predicted = np.zeros((Y_test.shape[0], 1))
rows = H_test_HotOne.shape[0]
cols = H_test_HotOne.shape[1]

for i in range(rows):
  for j in range(cols):
    if(H_test_HotOne[i][j] == 1):
      Y_test_Predicted[i][0] = j+1
      break

# Comparing Expected vs Prediction
print('EXPECTED vs PREDICTED')
print(np.concatenate((Y_test, Y_test_Predicted), axis=1))

# Calculating Accuracy
count = 0
for i in range(len(Y_test_Predicted)):
  if Y_test_Predicted[i] == Y_test[i]:
    count+=1;

print('Accuracy : ', (count/len(Y_test_Predicted))*100, '%')